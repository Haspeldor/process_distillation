anpassungen:
daten neu labeln -> fine tuning
neu labeln vs regularisierung
eigene loss funktion
regularisierer aus white box

grundlagenkapitel: 10-20 seiten
    - prelimenaries
        - neural network
        - PBPM
        - event logs
        - unfairness
    - related work

ansatz: vergleich mit debiasing und related work
    - siehe auch deren referenzen

aknowledgements:
    - personen und chatgpt angeben

todo:
    - transformer model maskieren
    - shapley score untersuchen

besprechen:
    - korrelierte attribute
    - log mit mehreren entscheidungen
    - shapley
        - aufwwändig zu berechnen
        - geht für geringe effekte verloren


60 seiten richtlinie
    - 20 methodology
    - 10 evaluation
    - 10 basics und related work